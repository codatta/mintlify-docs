<Tip>
### TL;DR

Codatta’s **human-centric** royalty economy + TNPL align **contributors**, **validators**, and **buyers** around **real model usage**. By converting data into shared, revenue-bearing assets—with verification-first QA, **recognition**, and a **Long-Term Success Index**—the ecosystem finally rewards the people who make AI better, while giving builders a flexible, lower-friction path to the data they need.

</Tip>

## What’s broken in the old model

Traditional labeling vendors (e.g., SaaS “workforce” platforms) centralize data and profits. Contributors are paid once, have **no ownership**, little recognition, and limited visibility into verification. That suppresses quality, makes rigorous validation expensive, and fails to attract the best experts.
Critically, today’s pipelines are not **human-centric**: they struggle to *find and retain qualified knowledge contributors* (lawyers, clinicians, researchers) whose work is more reliable and knowledge-rich. The incentives don’t match the skill/effort required, so “advanced intelligence workers” don’t show up—or don’t stay.

## Why demand is spiking now

* **Expert data bottlenecks:** Enterprises need vertical-grade data for LLMs/LVMs but can’t reliably mobilize and retain high-skill annotators. A **human-centric model** with recognition, ownership, and compounding upside changes that calculus.
* **LLM/AGI data hunger:** High-quality, verifiable annotation is now core infrastructure across industries.
* **Economics fit:** Data has durable future value via licensing or pay-as-you-go access—royalties are the natural settlement layer.

## What codatta changes

**Shared ownership → ongoing royalties.** codatta turns each contributed, verified data unit into a shared, on-chain asset. Ownership entitles contributors to a **stream of income** when that data is licensed/used, fixing the “paid once” problem and aligning effort with long-term value.

**Train-Now, Pay-Later (TNPL).** Instead of upfront data purchases, model builders can access data and **pay from downstream usage/results** (royalties/value-sharing). That lowers adoption friction for buyers while giving contributors upside over time.

**Human-centric sourcing.** The system is designed to **identify, attract, and keep qualified knowledge contributors**. Credential signals, track-record/performance, and curated task funnels surface the right people; **recognition + ownership + recurring upside** keep them engaged for the long haul.

**Verification-first quality engine (staking-as-confidence + reputation).** Verification is non-negotiable. Staking and reputation don’t replace QA—they **finance, prioritize, and enforce it**:

* Submit with evidence + provenance; stake signals confidence (and accountability).
* Automated checks flag anomalies; **blinded peer review** validates claims; disagreements auto-escalate.
* **Expert audit & cross-attestation** decide contested items; **identity/KYC** is used *only* when risk justifies it.
* Post-deployment challenges and error reports trigger re-verification; **stakes can be slashed** and royalties reallocated.
  This keeps verification as the gate while routing expert time to the highest-risk items—without walled-garden bottlenecks.

**Built-in economics.** Staking on **data** and **contributors** prices ownership fairly, routes revenue to the right parties, and rewards ongoing curation and maintenance—turning data from cost center into an *investable asset*.

## Who contributes—and why this model keeps them long-term

| Persona (qualification)      | What blocks them today                              | Why royalty + TNPL wins                                               | Long-term attitude fit                                                                                                   |
| ---------------------------- | --------------------------------------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| **Domain experts** (MD/JD/PhD)   | One-off fees; no attribution; high opportunity cost | Ownership + recurring royalties; **public recognition** for impact    | Experts value impact and credit; **ownership** + recognition align with professional pride and patient/ client outcomes. |
| **Senior analysts/curators**     | Limited career/brand benefit                        | Stake-backed **reputation**; revenue share for maintaining datasets   | Reputation compounds; **royalties** reward sustained quality and continuous improvement.                                 |
| **Community validators**         | Low trust; QA work under-rewarded                   | **Staking-as-confidence** pays for verification; clear accountability | Ongoing rewards for keeping data trustworthy; visible **trust signals** build standing over time.                        |
| **Tooling partners (index/RAG)** | No share in downstream value                        | TNPL contracts + **programmatic royalties** from usage                | Scales with model deployment without renegotiations; shared upside fosters long-term alignment.                          |

### Contributor Long-Term Success Index

To keep the model *human-centric*, codatta tracks a **Long-Term Success Index** per contributor—an internal score combining: (1) verification pass-rates and dispute survivability, (2) downstream usage/royalty accrual of their contributions, (3) peer/expert endorsements, and (4) consistency over time. LTSI powers better task routing, fairer revenue splits, and **recognition** that compounds contributors’ careers.

## Side-by-side: legacy vs. Codatta

| Dimension             | Legacy Human Intelligence SaaS    | Codatta royalty + TNPL                                               |
| --------------------- | --------------------------------- | -------------------------------------------------------------------- |
| Contributor upside    | One-off payments                  | **Recurring royalties** tied to real usage                           |
| Ownership/attribution | Centralized owner; opaque lineage | **Shared ownership**; on-chain attribution/lineage                   |
| Quality assurance     | Costly sampling; opaque QA        | **Verification-first** pipeline funded by **stakes** + staged checks |
| Talent access         | Can’t attract/retain top experts  | **Human-centric**: recognition, ownership, recurring upside          |
| Buyer cash flow       | Upfront data cost                 | **Train-Now, Pay-Later** (pay from outcomes/usage)                   |
| Sustainability        | Volume-driven, margin-capped      | Market-driven valuation; protocol-level incentives; **LTSI-guided**  |

